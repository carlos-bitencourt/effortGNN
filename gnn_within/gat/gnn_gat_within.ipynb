{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.neighbors import NearestNeighbors as SklearnNN\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, median_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.nn import GATConv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import copy\n",
    "import time\n",
    "import statistics\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amostras no df_sampled: 20757\n",
      "Amostras nos embeddings: 20757\n"
     ]
    }
   ],
   "source": [
    "node_features = np.load(\"../../pre_process/embeddings.npy\")\n",
    "df_sampled = pd.read_pickle(\"../../pre_process/df_sampled.pkl\")\n",
    "\n",
    "node_features = torch.tensor(node_features, dtype=torch.float32).clone().detach()\n",
    "print(\"Amostras no df_sampled:\", df_sampled.shape[0])\n",
    "print(\"Amostras nos embeddings:\", node_features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grafo intra-projeto criado (bidirecional):\n",
      "  - Nós: torch.Size([2796, 384])\n",
      "  - Arestas: torch.Size([2, 6500])\n"
     ]
    }
   ],
   "source": [
    "BERT_MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PROJECT_NAMES = {\n",
    "    36: \"MULE\",\n",
    "    43: \"EVG\",\n",
    "    12: \"TIMOB\",\n",
    "    4:  \"MESOS\"\n",
    "}\n",
    "PROJECT_ID = 36 # Projeto de teste MULE(36), EVG(43), TIMOB(12), MESOS(4)\n",
    "project_name = PROJECT_NAMES.get(PROJECT_ID, f\"project_{PROJECT_ID}\")\n",
    "VERSAO_MODELO = f\"gat_within_{project_name}\"\n",
    "\n",
    "# Carregar dados\n",
    "node_features_all = np.load(\"../../pre_process/embeddings.npy\")\n",
    "df_sampled = pd.read_pickle(\"../../pre_process/df_sampled.pkl\")\n",
    "\n",
    "# Filtrar apenas o projeto desejado\n",
    "df_project = df_sampled[df_sampled[\"Project_ID\"] == PROJECT_ID].copy().reset_index(drop=True)\n",
    "node_features = np.vstack(df_project[\"BERT_Embedding\"])\n",
    "\n",
    "node_features = torch.tensor(node_features, dtype=torch.float32).clone().detach()\n",
    "\n",
    "# Criar arestas kNN\n",
    "k = 4\n",
    "sknn = SklearnNN(n_neighbors=k, metric=\"cosine\").fit(node_features)\n",
    "_, indices = sknn.kneighbors(node_features)\n",
    "\n",
    "edges = []\n",
    "for i in range(len(df_project)):\n",
    "    for j in range(1, k):  # Ignora auto-loop\n",
    "        edges.append([i, indices[i, j]])\n",
    "\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).T\n",
    "\n",
    "# Tornar bidirecional\n",
    "edge_index_bi = torch.cat([edge_index, edge_index.flip(0)], dim=1)\n",
    "\n",
    "# Remover duplicatas se desejar (opcional, recomendado)\n",
    "sorted_edge_index = torch.stack([\n",
    "    torch.min(edge_index_bi[0], edge_index_bi[1]),\n",
    "    torch.max(edge_index_bi[0], edge_index_bi[1])\n",
    "], dim=0)\n",
    "\n",
    "edge_index_unique = torch.unique(sorted_edge_index, dim=1)\n",
    "\n",
    "# Criar o objeto PyG\n",
    "data = Data(\n",
    "    x=node_features,\n",
    "    edge_index=edge_index_unique\n",
    ")\n",
    "\n",
    "print(\"Grafo intra-projeto criado (bidirecional):\")\n",
    "print(\"  - Nós:\", data.x.shape)\n",
    "print(\"  - Arestas:\", data.edge_index.shape)\n",
    "\n",
    "\n",
    "# Função para filtrar subgrafos isolados\n",
    "def filter_edges_by_split(edge_index, train_idx, val_idx, test_idx):\n",
    "    allowed_train_val = set(train_idx.tolist() + val_idx.tolist())\n",
    "    allowed_test = set(test_idx.tolist())\n",
    "\n",
    "    filtered_edges = []\n",
    "\n",
    "    for src, dst in edge_index.T.tolist():\n",
    "        if (src in allowed_train_val and dst in allowed_train_val) or \\\n",
    "           (src in allowed_test and dst in allowed_test):\n",
    "            filtered_edges.append([src, dst])\n",
    "\n",
    "    return torch.tensor(filtered_edges, dtype=torch.long).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 10 runs (base seed=42)\n",
      "\n",
      "--- Run 1/10 (seed=42) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
      "  warnings.warn(f\"Using '{self.__class__.__name__}' without a \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10 Epoch 5/200 - Train Loss: 0.021274 - Val MSE: 0.019402"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_58886/4046924831.py\u001b[0m in \u001b[0;36m<cell line: 147>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_58886/4046924831.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch_geometric/nn/conv/gat_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[1;32m    345\u001b[0m                     \u001b[0mnum_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0mnum_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m                 edge_index, edge_attr = remove_self_loops(\n\u001b[0m\u001b[1;32m    348\u001b[0m                     edge_index, edge_attr)\n\u001b[1;32m    349\u001b[0m                 edge_index, edge_attr = add_self_loops(\n",
      "\u001b[0;32m/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch_geometric/utils/loop.py\u001b[0m in \u001b[0;36mremove_self_loops\u001b[0;34m(edge_index, edge_attr)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEdgeIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_undirected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_undirected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mis_scripting\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     r\"\"\"\n\u001b[1;32m    105\u001b[0m     \u001b[0mFunction\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompilation\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CONFIGURAÇÃO DE RUNS \n",
    "N_RUNS = 10\n",
    "OUT_DIR = f\"runs_results_{project_name}\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Hiperparâmetros \n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 200\n",
    "LEARNING_RATE = 1e-4\n",
    "DROPOUT = 0\n",
    "PATIENCE = 5\n",
    "NORMALIZE_TYPE = \"minmax\"  # \"minmax\", \"standard\", or None\n",
    "SEED = 42\n",
    "\n",
    "device = DEVICE  \n",
    "\n",
    "\n",
    "class GATModel(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, heads=2):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads)\n",
    "        self.conv2 = GATConv(hidden_channels * heads, hidden_channels, heads=1)  # ou outro heads\n",
    "\n",
    "        self.lin = nn.Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = torch.relu(self.conv1(x, edge_index))\n",
    "        x = torch.relu(self.conv2(x, edge_index))\n",
    "        return self.lin(x).view(-1)\n",
    "\n",
    "# Salvar backup do edge_index original (não filtrado)\n",
    "edge_index_orig = data.edge_index.cpu().clone().detach()\n",
    "\n",
    "# Funções utilitárias\n",
    "def set_all_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def prepare_split_and_loaders(seed, edge_index_backup):\n",
    "    \"\"\"\n",
    "    Restaura edge_index, cria split (70/15/15) com seed fornecida,\n",
    "    ajusta scaler somente com train, define data.y escalonado, e cria NeighborLoaders.\n",
    "    Retorna: scaler_fit, train_loader, val_loader, test_loader, train_idx, val_idx, test_idx\n",
    "    \"\"\"\n",
    "    # Restaura grafo global\n",
    "    data.edge_index = edge_index_backup.clone().to(data.x.device)\n",
    "\n",
    "    # Indices\n",
    "    all_indices = np.arange(data.num_nodes)\n",
    "\n",
    "    # Split \n",
    "    train_idx, temp_idx = train_test_split(all_indices, test_size=0.3, random_state=seed)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=seed)\n",
    "\n",
    "    # Ajustar scaler \n",
    "    sp_train = df_project.loc[train_idx, \"Story_Point\"].fillna(0).values.reshape(-1, 1)\n",
    "\n",
    "    if NORMALIZE_TYPE == \"minmax\":\n",
    "        scaler_local = MinMaxScaler().fit(sp_train)\n",
    "    elif NORMALIZE_TYPE == \"standard\":\n",
    "        scaler_local = StandardScaler().fit(sp_train)\n",
    "    else:\n",
    "        scaler_local = None\n",
    "\n",
    "    # Transformar todos os rótulos (train+val+test) com scaler ajustado no train\n",
    "    sp_all = df_project[\"Story_Point\"].fillna(0).values.reshape(-1, 1)\n",
    "    if scaler_local is not None:\n",
    "        sp_all_scaled = scaler_local.transform(sp_all).ravel()\n",
    "    else:\n",
    "        sp_all_scaled = sp_all.ravel()\n",
    "\n",
    "    data.y = torch.tensor(sp_all_scaled, dtype=torch.float32)\n",
    "\n",
    "    # Filtrar arestas entre grupos diferentes\n",
    "    data.edge_index = filter_edges_by_split(\n",
    "        edge_index=data.edge_index,\n",
    "        train_idx=train_idx,\n",
    "        val_idx=val_idx,\n",
    "        test_idx=test_idx\n",
    "    ).to(data.x.device)\n",
    "\n",
    "    # Criar loaders\n",
    "    train_loader = NeighborLoader(\n",
    "        data,\n",
    "        num_neighbors=[3,3],\n",
    "        batch_size=BATCH_SIZE,\n",
    "        input_nodes=torch.tensor(train_idx),\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_loader = NeighborLoader(\n",
    "        data,\n",
    "        num_neighbors=[3,3],\n",
    "        batch_size=BATCH_SIZE,\n",
    "        input_nodes=torch.tensor(val_idx),\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    test_loader = NeighborLoader(\n",
    "        data,\n",
    "        num_neighbors=[3,3],\n",
    "        batch_size=BATCH_SIZE,\n",
    "        input_nodes=torch.tensor(test_idx),\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return scaler_local, train_loader, val_loader, test_loader, train_idx, val_idx, test_idx\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = batch.to(device)\n",
    "            outputs = model(batch).cpu().numpy()\n",
    "            targets = batch.y.cpu().numpy()\n",
    "\n",
    "            loss = criterion(torch.tensor(outputs), torch.tensor(targets))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            predictions.extend(outputs)\n",
    "            actuals.extend(targets)\n",
    "\n",
    "    mae = mean_absolute_error(actuals, predictions)\n",
    "    mse = mean_squared_error(actuals, predictions)\n",
    "    mdae = median_absolute_error(actuals, predictions)\n",
    "    errors = np.abs(np.array(predictions) - np.array(actuals))\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        within_50 = np.where(np.array(actuals) != 0, errors <= (0.50 * np.array(actuals)), errors == 0)\n",
    "    pred_50 = float(np.mean(within_50))\n",
    "\n",
    "    return total_loss / max(1, len(dataloader)), float(mae), float(mse), float(mdae), float(pred_50)\n",
    "\n",
    "# Loop principal de runs \n",
    "all_run_results = []\n",
    "\n",
    "print(f\"Starting {N_RUNS} runs (base seed={SEED})\")\n",
    "for run_id in range(N_RUNS):\n",
    "    run_seed = SEED + run_id\n",
    "    set_all_seeds(run_seed)\n",
    "\n",
    "    # preparar dados / loaders (restaurando edge_index original)\n",
    "    scaler_run, train_loader, val_loader, test_loader, train_idx, val_idx, test_idx = prepare_split_and_loaders(run_seed, edge_index_orig)\n",
    "\n",
    "    # criar modelo novo para a run\n",
    "    in_channels = data.x.size(1)\n",
    "    hidden_dim = 64\n",
    "    model = GATModel(in_channels=in_channels, hidden_channels=hidden_dim, heads=2).to(device)\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", patience=(PATIENCE // 2)+1, factor=0.5)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "    train_losses = []\n",
    "    val_mse_history = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(f\"\\n--- Run {run_id+1}/{N_RUNS} (seed={run_seed}) ---\")\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch)\n",
    "            targets = batch.y.to(device)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_loss / max(1, len(train_loader))\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # validação\n",
    "        _, _, val_mse, *_ = evaluate_model(model, val_loader, criterion)\n",
    "        val_mse_history.append(val_mse)\n",
    "\n",
    "        print(f\"\\rRun {run_id+1}/{N_RUNS} Epoch {epoch+1}/{EPOCHS} - Train Loss: {avg_train_loss:.6f} - Val MSE: {val_mse:.6f}\", end=\"\", flush=True)\n",
    "\n",
    "        # early stopping logic\n",
    "        if val_mse < best_val_loss:\n",
    "            best_val_loss = val_mse\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        scheduler.step(val_mse)\n",
    "\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(f\"\\nEarly stopping (run {run_id+1}) after epoch {epoch+1}. Best Val MSE: {best_val_loss:.6f}\")\n",
    "            break\n",
    "\n",
    "    # restaura melhor modelo\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    # avaliação final no teste\n",
    "    _, mae_scaled, mse_scaled, mdae_scaled, pred50_scaled = evaluate_model(model, test_loader, criterion)\n",
    "\n",
    "    # converter métricas para escala real \n",
    "    if scaler_run is not None:\n",
    "        if NORMALIZE_TYPE == \"minmax\":\n",
    "            SP_MIN, SP_MAX = df_project[\"Story_Point\"].min(), df_project[\"Story_Point\"].max()\n",
    "            scale_factor = SP_MAX - SP_MIN\n",
    "            if scale_factor == 0:\n",
    "                scale_factor = 1.0\n",
    "            test_metrics_real = {\n",
    "                \"MAE\": mae_scaled * scale_factor,\n",
    "                \"MSE\": mse_scaled * (scale_factor ** 2),\n",
    "                \"MdAE\": mdae_scaled * scale_factor,\n",
    "                \"Pred(50)\": pred50_scaled\n",
    "            }\n",
    "        elif NORMALIZE_TYPE == \"standard\":\n",
    "            std_dev_real = df_project[\"Story_Point\"].std()\n",
    "            if std_dev_real == 0:\n",
    "                std_dev_real = 1.0\n",
    "            test_metrics_real = {\n",
    "                \"MAE\": mae_scaled * std_dev_real,\n",
    "                \"MSE\": mse_scaled * (std_dev_real ** 2),\n",
    "                \"MdAE\": mdae_scaled * std_dev_real,\n",
    "                \"Pred(50)\": pred50_scaled\n",
    "            }\n",
    "        else:\n",
    "            test_metrics_real = {\"MAE\": mae_scaled, \"MSE\": mse_scaled, \"MdAE\": mdae_scaled, \"Pred(50)\": pred50_scaled}\n",
    "    else:\n",
    "        test_metrics_real = {\"MAE\": mae_scaled, \"MSE\": mse_scaled, \"MdAE\": mdae_scaled, \"Pred(50)\": pred50_scaled}\n",
    "\n",
    "    # salvar resultados da run\n",
    "    run_result = {\n",
    "        \"run_id\": run_id + 1,\n",
    "        \"seed\": run_seed,\n",
    "        \"elapsed_sec\": elapsed,\n",
    "        \"best_val_mse\": float(best_val_loss),\n",
    "        \"epochs_trained\": epoch+1,\n",
    "        \"train_loss_history\": train_losses,\n",
    "        \"val_mse_history\": val_mse_history,\n",
    "        \"test_metrics_scaled\": {\"MAE\": float(mae_scaled), \"MSE\": float(mse_scaled), \"MdAE\": float(mdae_scaled), \"Pred(50)\": float(pred50_scaled)},\n",
    "        \"test_metrics_real\": {k: float(v) for k, v in test_metrics_real.items()}\n",
    "    }\n",
    "\n",
    "    # salvar arquivo json e pesos\n",
    "    json_path = os.path.join(OUT_DIR, f\"{VERSAO_MODELO}_run{run_id+1}_seed{run_seed}.json\")\n",
    "    torch_path = os.path.join(OUT_DIR, f\"{VERSAO_MODELO}_run{run_id+1}_seed{run_seed}.pt\")\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(run_result, f, indent=4)\n",
    "    torch.save(best_model_state, torch_path)\n",
    "\n",
    "    all_run_results.append(run_result)\n",
    "\n",
    "    # liberar cache GPU\n",
    "    try:\n",
    "        torch.cuda.empty_cache()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# --- Consolidação final ---\n",
    "maes = [r[\"test_metrics_real\"][\"MAE\"] for r in all_run_results]\n",
    "mses = [r[\"test_metrics_real\"][\"MSE\"] for r in all_run_results]\n",
    "mdaes = [r[\"test_metrics_real\"][\"MdAE\"] for r in all_run_results]\n",
    "pred50s = [r[\"test_metrics_real\"][\"Pred(50)\"] for r in all_run_results]\n",
    "\n",
    "summary = {\n",
    "    \"n_runs\": N_RUNS,\n",
    "    \"seed_base\": SEED,\n",
    "    \"MAE_mean\": float(statistics.mean(maes)),\n",
    "    \"MAE_std\": float(statistics.pstdev(maes)),\n",
    "    \"MSE_mean\": float(statistics.mean(mses)),\n",
    "    \"MSE_std\": float(statistics.pstdev(mses)),\n",
    "    \"MdAE_mean\": float(statistics.mean(mdaes)),\n",
    "    \"MdAE_std\": float(statistics.pstdev(mdaes)),\n",
    "    \"Pred50_mean\": float(statistics.mean(pred50s)),\n",
    "    \"Pred50_std\": float(statistics.pstdev(pred50s)),\n",
    "    \"per_run_files\": [os.path.basename(f\"{VERSAO_MODELO}_run{r['run_id']}_seed{r['seed']}.json\") for r in all_run_results]\n",
    "}\n",
    "\n",
    "summary_path = os.path.join(OUT_DIR, f\"{VERSAO_MODELO}_summary_{N_RUNS}runs.json\")\n",
    "with open(summary_path, \"w\") as f:\n",
    "    json.dump({\"summary\": summary, \"runs\": all_run_results}, f, indent=4)\n",
    "\n",
    "print(\"\\nAll runs finished.\")\n",
    "print(\"Summary saved to:\", summary_path)\n",
    "print(\"MAE mean (real scale):\", summary[\"MAE_mean\"], \"±\", summary[\"MAE_std\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Docker)",
   "language": "python",
   "name": "python_docker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
